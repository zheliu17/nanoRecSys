{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Production Training (Temporal Split)\n",
    "\n",
    "This notebook implements a complete \"Production\" pipeline, simulating a real-world deployment scenario for a two-stage recommender system.\n",
    "\n",
    "**Pipeline Steps:**\n",
    "1. **Data Processing:** Load MovieLens data and split temporally (train on past, test on future).\n",
    "2. **Retriever Training:** Train a Two-Tower model to retrieve candidates.\n",
    "3. **Hard Negative Mining:** Use the trained retriever to find \"hard\" negatives (items the model incorrectly thinks are relevant) for the ranker.\n",
    "4. **Ranker Training:** Train a Cross-Encoder model to re-rank the candidates.\n",
    "5. **Evaluation:** Evaluate the full pipeline on the held-out test set (last 5 interactions per user).\n",
    "\n",
    "**Key Characteristics:**\n",
    "* **Rating Threshold:** Only interactions with ratings >= 3.5 are considered positive.\n",
    "* **Real-world Simulation:** Strict temporal split avoids data leakage.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup (Colab)\n",
    "Run the following cell to install the package and dependencies if running in Google Colab.\n",
    "If running locally, ensure you have installed the package via `pip install -e .`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 620
    },
    "id": "pVBK-db6-IUU",
    "outputId": "2c4d0c58-5591-49c0-bc7f-e1f4fa1c6642"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/zheliu17/nanoRecSys.git\n",
    "%pip install -q -e ./nanoRecSys\n",
    "\n",
    "import psutil  # noqa: F401\n",
    "\n",
    "# In fact, we don't need psutil. force-reinstall to trigger colab restart\n",
    "%pip install --force-reinstall psutil=={psutil.__version__}\n",
    "print(\"Installation complete. Please restart runtime...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7mrL1Mq5AXx-",
    "outputId": "dbd2f807-676a-418f-ad0c-f77fce1c22e6"
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "import nanoRecSys.data.build_dataset\n",
    "import nanoRecSys.data.splits\n",
    "\n",
    "wandb.login()\n",
    "\n",
    "nanoRecSys.data.build_dataset.process_data()\n",
    "nanoRecSys.data.splits.create_user_time_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "6f631e1e0a424930a755332d14cd4f8e",
      "d2cfd0ff5fb9428d9d004e3906a5c230"
     ]
    },
    "id": "O_a9X5g4AYID",
    "outputId": "f75fbb9f-3a09-4b59-fc6c-8e30ab928b21"
   },
   "outputs": [],
   "source": [
    "import nanoRecSys.train\n",
    "\n",
    "\n",
    "# Retriever Training Arguments\n",
    "class Args:\n",
    "    mode = \"retriever\"\n",
    "    epochs = 5\n",
    "    batch_size = 4096\n",
    "    lr = 4e-2\n",
    "    num_workers = 2\n",
    "    build_embeddings = True  # Build embeddings for fast retrieval after training\n",
    "\n",
    "\n",
    "nanoRecSys.train.main(Args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negative Mining & Ranker Training\n",
    "We use the trained retriever to mine hard negatives (items that the retriever assigns high scores to, but are not the ground truth interaction).  The Ranker is then trained to distinguish between the positive item and these hard negatives.\n",
    "The Ranker is a Cross-Encoder that takes both User and Item features as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "71afd9e7e22140ee934ad09994509b7a",
      "c44f696ba9a245c58cf4cba6b94ab387"
     ]
    },
    "id": "SPMUOBJlQKpp",
    "outputId": "76b5046a-2a79-48ea-b0c8-70e740cf98f4"
   },
   "outputs": [],
   "source": [
    "import nanoRecSys.training.mine_negatives\n",
    "\n",
    "nanoRecSys.training.mine_negatives.main(batch_size=1024, top_k=15, skip_top=0)\n",
    "\n",
    "\n",
    "class Args:\n",
    "    mode = \"ranker\"\n",
    "    epochs = 1\n",
    "    limit_train_batches = 0.5\n",
    "    batch_size = 2048\n",
    "    explicit_neg_weight = 4\n",
    "    random_neg_ratio = 0.01\n",
    "\n",
    "    lr = 1e-3\n",
    "    item_lr = 0\n",
    "    num_workers = 2\n",
    "\n",
    "\n",
    "nanoRecSys.train.main(Args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "We evaluate the full pipeline (Retriever + Ranker) on the held-out test set (last 5 interactions).\n",
    "First, we look at the **Popularity Baseline** to establish a lower bound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 261
    },
    "id": "UDwpw1icSosH",
    "outputId": "eac0a950-a911-4829-e3d9-7222704e668d"
   },
   "outputs": [],
   "source": [
    "from nanoRecSys.eval.offline_eval import OfflineEvaluator\n",
    "\n",
    "evaluator = OfflineEvaluator(1024)\n",
    "results = evaluator.eval_popularity()\n",
    "\n",
    "df = evaluator.formatted_results(results)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we evaluate the full **Ranker** model. Typically, re-ranking should improve metrics (NDCG, Recall) over pure retrieval or popularity baselines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 351
    },
    "id": "4T7n5oKOSk8Z",
    "outputId": "ed4b06d9-97b5-4be6-e677-5b9cb538281b"
   },
   "outputs": [],
   "source": [
    "results = evaluator.eval_ranker()\n",
    "\n",
    "df = evaluator.formatted_results(results)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
