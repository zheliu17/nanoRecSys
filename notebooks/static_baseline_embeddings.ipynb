{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline: Matrix Factorization with InfoNCE\n",
    "\n",
    "**NOTE: This notebook demonstrates the legacy MLP-based Two-Tower model. For the state-of-the-art Sequential Transformer, see `sequential_transformer.ipynb`.**\n",
    "\n",
    "This is an easy-to-train baseline (bi-encoder).\n",
    "\n",
    "`Users -> Embedding` | `Items -> Embedding`  -> Cosine Similarity -> InfoNCE Loss\n",
    "\n",
    "*   **Architecture:** Shallow MLP (or just embeddings). No deep sequence modeling.\n",
    "*   **Training Time:** ~5 minutes on GPU.\n",
    "*   **Performance:** ~50% improvement over NCF (Neural Collaborative Filtering), but significantly lower than the Sequential Transformer.\n",
    "\n",
    "### Protocol\n",
    "*   **Data Split:** Leave-One-Out (LOO).\n",
    "*   **Positive Samples:** All interactions treated as implicit feedback.\n",
    "*   **Metrics:** HR@10, NDCG@10 (Sampled Evaluation against 100 negatives + 1 positive).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup (Colab)\n",
    "Run the following cell to install the package and dependencies if running in Google Colab.\n",
    "If running locally, ensure you have installed the package via `pip install -e .`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617
    },
    "id": "lDO4lCJ4TnZi",
    "outputId": "d31efb74-0cb0-4c70-864e-0d050ee3e399"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/zheliu17/nanoRecSys.git\n",
    "%pip install -q -e ./nanoRecSys\n",
    "\n",
    "import psutil  # noqa: F401\n",
    "\n",
    "# In fact, we don't need psutil. force-reinstall to trigger colab restart\n",
    "%pip install --force-reinstall psutil=={psutil.__version__}\n",
    "print(\"Installation complete. Please restart runtime...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LHC4VLq1UB5f",
    "outputId": "0241f40e-218d-423a-e775-09680f567ee1"
   },
   "outputs": [],
   "source": [
    "import nanoRecSys.data.build_dataset\n",
    "import nanoRecSys.data.splits\n",
    "\n",
    "nanoRecSys.data.build_dataset.process_data()\n",
    "nanoRecSys.data.splits.create_user_time_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "256d17cca0ec4e87abb6febed482db21",
      "e89a0c4f91e94e26aa318299d9605dca"
     ]
    },
    "id": "C2vP6LeuUbt2",
    "outputId": "1071ed8d-b32b-40c6-b88f-a63a8e303b42"
   },
   "outputs": [],
   "source": [
    "import nanoRecSys.train\n",
    "\n",
    "\n",
    "class Args:\n",
    "    mode = \"retriever\"\n",
    "    user_tower_type = \"mlp\"\n",
    "\n",
    "    epochs = 3\n",
    "    check_val_every_n_epoch = 1\n",
    "    batch_size = 4096\n",
    "    adam_beta2 = 0.999\n",
    "\n",
    "    lr = 0.05\n",
    "    num_workers = 2\n",
    "\n",
    "\n",
    "nanoRecSys.train.main(Args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uirFt5HSdcjZ"
   },
   "source": [
    "Evaluate the popularity baseline:\n",
    "\n",
    "\n",
    "Note: \n",
    "- Sampled evaluation, not full ranking. Number below are comparable to https://arxiv.org/abs/1904.06690\n",
    "- MRR in paper is global MRR, and should be compared to MRR@100 here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 574
    },
    "id": "qLUBL6lgUTa1",
    "outputId": "2506d6cf-5af8-42ef-df12-9595cae24062"
   },
   "outputs": [],
   "source": [
    "from nanoRecSys.eval.offline_eval import OfflineEvaluator\n",
    "\n",
    "evaluator = OfflineEvaluator(1024, sampled=True, sample_strategy=\"popularity\")\n",
    "results = evaluator.eval_popularity()\n",
    "\n",
    "df = evaluator.formatted_results(results)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aFvGpWaOfJKb"
   },
   "source": [
    "Evaluate our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 261
    },
    "id": "5CYUtKUdfF9N",
    "outputId": "1b367dbc-b1c4-4108-cf83-3baffa843f42"
   },
   "outputs": [],
   "source": [
    "results = evaluator.eval_retrieval()\n",
    "df = evaluator.formatted_results(results)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results:\n",
    "\n",
    "|        | HR@10  | NDCG@10 | MRR (Global)   |\n",
    "|--------|--------|---------|--------|\n",
    "| Popularity| 0.1426 |  0.0717 | 0.0722 |\n",
    "| NeuCF    | 0.2922 | 0.1271  | 0.1072 |\n",
    "| **Ours**   | **0.4392** |  **0.232** | **0.1916** |"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
